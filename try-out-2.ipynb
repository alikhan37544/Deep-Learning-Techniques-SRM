{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing different cross-validation techniques on the Iris dataset, each method offers unique advantages and potential insights into model performance. Here's an inference based on using these four methods:\n",
    "\n",
    "1. *Hold Out Cross-Validation*:\n",
    "    - *Method*: The dataset is split into two parts: training and testing. Typically, a common split is 80/20 or 70/30.\n",
    "    - *Inference*: This method is simple and quick but can be subject to variability depending on the split. If the training and testing sets are not representative, the model performance might be misleading. It provides a snapshot of model performance but doesn't utilize the entire dataset for training.\n",
    "\n",
    "2. *K-Fold Cross-Validation*:\n",
    "    - *Method*: The dataset is divided into k equal parts. The model is trained on k-1 parts and tested on the remaining part. This process is repeated k times, with each part used exactly once as the testing set.\n",
    "    - *Inference*: K-Fold cross-validation provides a more reliable estimate of model performance compared to hold-out validation. By training and testing on different subsets of the data, it reduces the variance in performance estimation. It ensures that every data point is used for both training and testing, providing a more comprehensive assessment.\n",
    "\n",
    "3. *Stratified K-Fold Cross-Validation*:\n",
    "    - *Method*: Similar to K-Fold, but the data is split in such a way that each fold has approximately the same proportion of classes as the entire dataset.\n",
    "    - *Inference*: Stratified K-Fold is especially useful for imbalanced datasets. For the Iris dataset, which has balanced classes, it ensures that each fold is representative of the overall class distribution. This typically leads to more stable and reliable performance metrics compared to regular K-Fold, especially if there are any minor imbalances.\n",
    "\n",
    "4. *Leave One Out Cross-Validation (LOOCV)*:\n",
    "    - *Method*: Each data point is used once as a test set while the remaining data points are used as the training set. This process is repeated for every data point in the dataset.\n",
    "    - *Inference*: LOOCV uses the maximum amount of data for training in each iteration, providing a very thorough assessment. However, it is computationally expensive and can be impractical for large datasets. For the Iris dataset, LOOCV would be feasible and could provide very detailed insights into model performance but might overestimate variance due to the high number of splits.\n",
    "\n",
    "*Overall Comparison*:\n",
    "- *Hold Out*: Quick and simple but less reliable due to potential data split variability.\n",
    "- *K-Fold*: Balances between computational efficiency and reliable performance estimation.\n",
    "- *Stratified K-Fold*: Enhances K-Fold by ensuring class distribution consistency across folds, providing more stable results.\n",
    "- *LOOCV*: Provides the most detailed and least biased performance estimate but is computationally intensive.\n",
    "\n",
    "For the Iris dataset, which is relatively small and balanced, *Stratified K-Fold* cross-validation often strikes the best balance between reliability and computational efficiency, ensuring that each fold is representative of the overall class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Dataset 150\n",
      "Accuracy score on training set is0.9619047619047619\n",
      "Accuracy score on test set is 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris=load_iris()\n",
    "X=iris.data\n",
    "Y=iris.target\n",
    "print(\"Size of Dataset {}\".format(len(X)))\n",
    "logreg=LogisticRegression()\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=42)\n",
    "logreg.fit(x_train,y_train)\n",
    "predict=logreg.predict(x_test)\n",
    "print(\"Accuracy score on training set is{}\".format(accuracy_score(logreg.predict(x_train),y_train)))\n",
    "print(\"Accuracy score on test set is {}\".format(accuracy_score(predict,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores are [1.         1.         0.86666667 0.93333333 0.83333333]\n",
      "Average Cross Validation score :0.9266666666666665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "iris=load_iris()\n",
    "X=iris.data\n",
    "Y=iris.target\n",
    "logreg=LogisticRegression()\n",
    "kf=KFold(n_splits=5)\n",
    "score=cross_val_score(logreg,X,Y,cv=kf)\n",
    "print(\"Cross Validation Scores are {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores are [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "Average Cross Validation score :0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut,cross_val_score\n",
    "iris=load_iris()\n",
    "X=iris.data\n",
    "Y=iris.target\n",
    "loo=LeaveOneOut()\n",
    "tree=RandomForestClassifier(n_estimators=10,max_depth=5,n_jobs=-1)\n",
    "score=cross_val_score(tree,X,Y,cv=loo)\n",
    "print(\"Cross Validation Scores are {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
